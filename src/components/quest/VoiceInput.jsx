import { useState, useRef, useEffect } from 'react';
import { Mic, MicOff, Loader2, Sparkles } from 'lucide-react';
import { base44 } from '@/api/base44Client';

export default function VoiceInput({ onQuestsGenerated }) {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [audioLevels, setAudioLevels] = useState([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]);
  const recognitionRef = useRef(null);
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const animationFrameRef = useRef(null);

  useEffect(() => {
    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
    };
  }, []);

  const startAudioVisualization = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const analyser = audioContext.createAnalyser();
      const microphone = audioContext.createMediaStreamSource(stream);
      
      analyser.fftSize = 32;
      microphone.connect(analyser);
      
      audioContextRef.current = audioContext;
      analyserRef.current = analyser;

      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      
      const updateLevels = () => {
        analyser.getByteFrequencyData(dataArray);
        
        // Sample 10 bars from the frequency data
        const levels = [];
        const step = Math.floor(dataArray.length / 10);
        for (let i = 0; i < 10; i++) {
          const value = dataArray[i * step] / 255;
          levels.push(Math.min(value * 1.5, 1)); // Amplify slightly
        }
        
        setAudioLevels(levels);
        animationFrameRef.current = requestAnimationFrame(updateLevels);
      };
      
      updateLevels();
    } catch (error) {
      console.error('æ— æ³•è®¿é—®éº¦å…‹é£:', error);
    }
  };

  const stopAudioVisualization = () => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
    }
    setAudioLevels([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]);
  };

  const startRecording = async () => {
    try {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      
      if (!SpeechRecognition) {
        alert('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼Œè¯·ä½¿ç”¨æ–‡æœ¬è¾“å…¥');
        return;
      }

      const recognition = new SpeechRecognition();
      recognition.lang = 'zh-CN';
      recognition.continuous = true;
      recognition.interimResults = true;

      recognition.onstart = () => {
        setIsRecording(true);
        startAudioVisualization();
        console.log('è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨');
      };

      recognition.onresult = (event) => {
        let interimTranscript = '';
        let finalTranscript = '';

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          } else {
            interimTranscript += transcript;
          }
        }

        setTranscript(finalTranscript || interimTranscript);
      };

      recognition.onerror = (event) => {
        console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);
        setIsRecording(false);
        stopAudioVisualization();
        if (event.error === 'no-speech') {
          alert('æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•');
        } else if (event.error === 'not-allowed') {
          alert('éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸ä½¿ç”¨éº¦å…‹é£');
        } else {
          alert(`è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼š${event.error}`);
        }
      };

      recognition.onend = () => {
        setIsRecording(false);
        stopAudioVisualization();
        console.log('è¯­éŸ³è¯†åˆ«å·²ç»“æŸ');
      };

      recognitionRef.current = recognition;
      recognition.start();
    } catch (error) {
      console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      alert('æ— æ³•å¯åŠ¨è¯­éŸ³è¯†åˆ«ï¼Œè¯·æ£€æŸ¥æµè§ˆå™¨æƒé™');
    }
  };

  const stopRecording = async () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      setIsRecording(false);
      stopAudioVisualization();
      
      if (transcript.trim()) {
        await handleTextSubmit(transcript);
      }
    }
  };

  const handleTextSubmit = async (text) => {
    if (!text.trim()) return;
    
    setIsProcessing(true);
    try {
      const result = await base44.integrations.Core.InvokeLLM({
        prompt: `ä½ æ˜¯å†’é™©è€…å·¥ä¼šçš„AIåŠ©æ‰‹ã€‚ç”¨æˆ·è¾“å…¥äº†ä»»åŠ¡æè¿°ï¼š"${text}"

è¯·å°†å…¶è§£æä¸ºRPGé£æ ¼çš„ç»“æ„åŒ–ä»»åŠ¡ã€‚

ã€é‡è¦è§„åˆ™ã€‘actionHintï¼ˆæ‹¬å·å†…å®¹ï¼‰å¿…é¡»å¿ å®åŸè¯ï¼š
- ä¿ç•™æ‰€æœ‰å…³é”®è¯ï¼ˆäººåã€åœ°ç‚¹ã€å…·ä½“äº‹é¡¹ã€å¹³å°åç§°ç­‰ï¼‰
- åªåšå¿…è¦çš„ç®€åŒ–ï¼Œä¸è¦æ”¹å†™æ„æ€
- å¦‚æœæœ‰æ—¶é—´ä¿¡æ¯ï¼Œç”¨@HH:MMæ ¼å¼æ ‡æ³¨
- ä¾‹ï¼š
  "å›å¤ç¾¤é‡Œçš„ä¿¡æ¯" â†’ actionHint: "å›å¤ç¾¤æ¶ˆæ¯"ï¼ˆä¿ç•™"ç¾¤"ï¼‰
  "ç»™Daisyå‘é‚®ä»¶ç¡®è®¤çœ‹æˆ¿" â†’ actionHint: "ç»™Daisyå‘çœ‹æˆ¿ç¡®è®¤é‚®ä»¶"ï¼ˆä¿ç•™äººåå’Œå…·ä½“äº‹é¡¹ï¼‰
  "æ˜æ—©7ç‚¹è·‘æ­¥5å…¬é‡Œ" â†’ actionHint: "è·‘æ­¥5km@07:00"

RPGæ ‡é¢˜å‘½åè§„åˆ™ï¼š
1. æ ¼å¼ï¼šã€ä»»åŠ¡ç±»å‹ã€‘ä»»åŠ¡åç§°
   - ä»»åŠ¡ç±»å‹ï¼šè®¨ä¼ã€æ”¶é›†ã€æŠ¤é€ã€è°ƒæŸ¥ã€ä¿®ç‚¼ã€å¾æœã€æ¢ç´¢
2. æ ‡é¢˜è¦æœ‰åœºæ™¯æ„Ÿå’Œæˆå‰§æ€§ï¼Œä½†ä¸è¦è¿‡åº¦ä¿®é¥°

éš¾åº¦è¯„çº§ï¼ˆ4ä¸ªç­‰çº§ï¼‰ï¼š
- Cçº§ï¼šè½»æ¾ä»»åŠ¡ï¼ˆæ—¥å¸¸çäº‹ã€ç®€å•äº‹é¡¹ï¼‰
- Bçº§ï¼šä¸­ç­‰æŒ‘æˆ˜ï¼ˆéœ€è¦ä¸€äº›åŠªåŠ›å’Œæ—¶é—´ï¼‰
- Açº§ï¼šé«˜éš¾åº¦ï¼ˆçªç ´èˆ’é€‚åŒºã€æœ‰æŒ‘æˆ˜æ€§ï¼‰
- Sçº§ï¼šè¶…çº§æŒ‘æˆ˜ï¼ˆäººç”Ÿé‡å¤§ä»»åŠ¡ã€æå…·éš¾åº¦ï¼‰

ç¤ºä¾‹ï¼š
è¾“å…¥ï¼š"å†™å‘¨æŠ¥"
è¾“å‡ºï¼š
{
  "quests": [
    {
      "title": "ã€è®°å½•ã€‘å†’é™©å‘¨å¿—ç¼–æ’°",
      "actionHint": "å†™å‘¨æŠ¥",
      "tags": ["å·¥ä½œ"],
      "difficulty": "C",
      "rarity": "Common"
    }
  ]
}

è¾“å…¥ï¼š"å¼€å§‹æ¯å¤©è·‘æ­¥5å…¬é‡Œçš„ä¹ æƒ¯"
è¾“å‡ºï¼š
{
  "quests": [
    {
      "title": "ã€ä¿®ç‚¼ã€‘æ™¨æ›¦é•¿è·‘è¯•ç‚¼",
      "actionHint": "è·‘æ­¥5km",
      "tags": ["è¿åŠ¨", "ä¹ æƒ¯"],
      "difficulty": "A",
      "rarity": "Rare"
    }
  ]
}

è¯·å¤„ç†ç”¨æˆ·è¾“å…¥ã€‚`,
        response_json_schema: {
          type: "object",
          properties: {
            quests: {
              type: "array",
              items: {
                type: "object",
                properties: {
                  title: { type: "string" },
                  actionHint: { type: "string" },
                  dueDate: { type: "string" },
                  tags: { type: "array", items: { type: "string" } },
                  difficulty: { type: "string", enum: ["C", "B", "A", "S"] },
                  rarity: { type: "string", enum: ["Common", "Rare", "Epic", "Legendary"] }
                }
              }
            }
          }
        }
      });

      onQuestsGenerated(result.quests || []);
      setTranscript('');
    } catch (error) {
      console.error('æ–‡æœ¬å¤„ç†é”™è¯¯:', error);
      alert(`ä»»åŠ¡è§£æå¤±è´¥ï¼š${error.message || 'è¯·é‡è¯•'}`);
    }
    setIsProcessing(false);
  };

  return (
    <div 
      className="p-4 mb-6"
      style={{
        backgroundColor: '#FFE66D',
        border: '4px solid #000',
        boxShadow: '6px 6px 0px #000'
      }}
    >
      {!isRecording ? (
        // Default Input Mode
        <div className="flex gap-3 mb-3">
          <button
            onClick={startRecording}
            disabled={isProcessing}
            className="flex-shrink-0 w-16 h-16 flex items-center justify-center font-black transition-all"
            style={{
              backgroundColor: '#4ECDC4',
              border: '4px solid #000',
              boxShadow: '5px 5px 0px #000'
            }}
          >
            {isProcessing ? (
              <Loader2 className="w-8 h-8 animate-spin" />
            ) : (
              <Mic className="w-8 h-8" strokeWidth={3} />
            )}
          </button>

          <div className="flex-1">
            <input
              type="text"
              placeholder="è¾“å…¥ä»»åŠ¡æˆ–ç‚¹å‡»éº¦å…‹é£è¯´è¯..."
              value={transcript}
              onChange={(e) => setTranscript(e.target.value)}
              onKeyPress={(e) => {
                if (e.key === 'Enter') {
                  handleTextSubmit(transcript);
                }
              }}
              disabled={isProcessing}
              className="w-full h-16 px-4 font-bold text-lg"
              style={{
                backgroundColor: '#FFF',
                border: '4px solid #000',
                boxShadow: '5px 5px 0px #000'
              }}
            />
          </div>

          <button
            onClick={() => handleTextSubmit(transcript)}
            disabled={isProcessing || !transcript.trim()}
            className="flex-shrink-0 w-16 h-16 flex items-center justify-center font-black"
            style={{
              backgroundColor: '#C44569',
              color: '#FFF',
              border: '4px solid #000',
              boxShadow: '5px 5px 0px #000',
              opacity: (!transcript.trim() || isProcessing) ? 0.5 : 1
            }}
          >
            <Sparkles className="w-8 h-8" strokeWidth={3} />
          </button>
        </div>
      ) : (
        // Voice Recording Mode with Waveform
        <div className="mb-3">
          <div 
            className="p-6 mb-3"
            style={{
              backgroundColor: '#FFF',
              border: '4px solid #000',
              boxShadow: '5px 5px 0px #000'
            }}
          >
            {/* Waveform Visualization */}
            <div className="flex items-end justify-center gap-1 mb-4" style={{ height: '80px' }}>
              {audioLevels.map((level, i) => (
                <div
                  key={i}
                  className="transition-all duration-100 ease-out"
                  style={{
                    width: '8%',
                    height: `${Math.max(level * 100, 10)}%`,
                    backgroundColor: '#FF6B35',
                    border: '2px solid #000',
                    boxShadow: '2px 2px 0px #000'
                  }}
                />
              ))}
            </div>

            {/* Real-time Transcript */}
            <div className="min-h-[40px] flex items-center justify-center">
              {transcript ? (
                <p className="font-bold text-lg text-center">{transcript}</p>
              ) : (
                <p className="font-bold text-gray-400 text-center">æ­£åœ¨è†å¬...</p>
              )}
            </div>
          </div>

          {/* Stop Button */}
          <button
            onClick={stopRecording}
            className="w-full py-4 font-black uppercase text-lg flex items-center justify-center gap-3"
            style={{
              backgroundColor: '#FF6B35',
              color: '#FFF',
              border: '4px solid #000',
              boxShadow: '5px 5px 0px #000'
            }}
          >
            <MicOff className="w-6 h-6" strokeWidth={3} />
            å®Œæˆå½•éŸ³
          </button>
        </div>
      )}

      <p className="text-xs font-bold uppercase tracking-wide" style={{ color: '#000' }}>
        ğŸ’¡ è¯´å‡ºä½ çš„ä»»åŠ¡ï¼Œå·¥ä¼šAIå°†ä¸ºä½ æ•´ç†ï¼
      </p>
    </div>
  );
}