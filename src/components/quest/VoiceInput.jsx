import { useState, useRef, useEffect } from 'react';
import { Mic, MicOff, Loader2, Sparkles, AlertCircle } from 'lucide-react';
import { base44 } from '@/api/base44Client';

export default function VoiceInput({ onQuestsGenerated }) {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [confidence, setConfidence] = useState(1);
  const [audioLevels, setAudioLevels] = useState([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]);
  const recognitionRef = useRef(null);
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const animationFrameRef = useRef(null);
  const streamRef = useRef(null);

  useEffect(() => {
    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  const startAudioVisualization = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;
      
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const analyser = audioContext.createAnalyser();
      const microphone = audioContext.createMediaStreamSource(stream);
      
      analyser.fftSize = 32;
      microphone.connect(analyser);
      
      audioContextRef.current = audioContext;
      analyserRef.current = analyser;

      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      
      const updateLevels = () => {
        if (!analyserRef.current) return;
        
        analyserRef.current.getByteFrequencyData(dataArray);
        
        const levels = [];
        const step = Math.floor(dataArray.length / 10);
        for (let i = 0; i < 10; i++) {
          const value = dataArray[i * step] / 255;
          levels.push(Math.min(value * 1.5, 1));
        }
        
        setAudioLevels(levels);
        animationFrameRef.current = requestAnimationFrame(updateLevels);
      };
      
      updateLevels();
    } catch (error) {
      console.error('æ— æ³•è®¿é—®éº¦å…‹é£:', error);
    }
  };

  const stopAudioVisualization = () => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    analyserRef.current = null;
    setAudioLevels([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]);
  };

  const startRecording = async () => {
    try {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      
      if (!SpeechRecognition) {
        alert('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼Œè¯·ä½¿ç”¨æ–‡æœ¬è¾“å…¥');
        return;
      }

      const recognition = new SpeechRecognition();
      
      // é…ç½®å¤šè¯­è¨€æ”¯æŒï¼Œæå‡å£éŸ³è¯†åˆ«
      recognition.lang = 'zh-CN';
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.maxAlternatives = 3; // è·å–å¤šä¸ªå€™é€‰ç»“æœ

      recognition.onstart = () => {
        setIsRecording(true);
        startAudioVisualization();
        console.log('è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨');
      };

      recognition.onresult = (event) => {
        let interimTranscript = '';
        let finalTranscript = '';
        let avgConfidence = 0;
        let confidenceCount = 0;

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const result = event.results[i];
          const transcriptText = result[0].transcript;
          
          // æ”¶é›†ç½®ä¿¡åº¦
          if (result[0].confidence !== undefined) {
            avgConfidence += result[0].confidence;
            confidenceCount++;
          }
          
          if (result.isFinal) {
            finalTranscript += transcriptText;
          } else {
            interimTranscript += transcriptText;
          }
        }

        // è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        if (confidenceCount > 0) {
          setConfidence(avgConfidence / confidenceCount);
        }

        setTranscript(finalTranscript || interimTranscript);
      };

      recognition.onerror = (event) => {
        console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);
        setIsRecording(false);
        stopAudioVisualization();
        if (event.error === 'no-speech') {
          alert('æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•');
        } else if (event.error === 'not-allowed') {
          alert('éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸ä½¿ç”¨éº¦å…‹é£');
        } else {
          alert(`è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼š${event.error}`);
        }
      };

      recognition.onend = () => {
        setIsRecording(false);
        stopAudioVisualization();
        console.log('è¯­éŸ³è¯†åˆ«å·²ç»“æŸ');
      };

      recognitionRef.current = recognition;
      recognition.start();
    } catch (error) {
      console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      alert('æ— æ³•å¯åŠ¨è¯­éŸ³è¯†åˆ«ï¼Œè¯·æ£€æŸ¥æµè§ˆå™¨æƒé™');
    }
  };

  const stopRecording = async () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      setIsRecording(false);
      stopAudioVisualization();
      
      if (transcript.trim()) {
        await handleTextSubmit(transcript, confidence);
      }
    }
  };

  const handleTextSubmit = async (text, conf = 1) => {
    if (!text.trim()) return;
    
    setIsProcessing(true);
    try {
      // ä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰ç†è§£å’Œå£éŸ³çº æ­£
      const result = await base44.integrations.Core.InvokeLLM({
        prompt: `ä½ æ˜¯å†’é™©è€…å·¥ä¼šçš„AIä¹¦è®°å®˜ï¼Œè´Ÿè´£è®°å½•å§”æ‰˜ã€‚ç”¨æˆ·é€šè¿‡è¯­éŸ³è¾“å…¥ä»»åŠ¡ï¼Œå¯èƒ½å¸¦æœ‰å£éŸ³æˆ–å‘éŸ³ä¸æ ‡å‡†ã€‚

ã€åŸå§‹è¯­éŸ³æ–‡æœ¬ã€‘ï¼š"${text}"
ã€è¯†åˆ«ç½®ä¿¡åº¦ã€‘ï¼š${(conf * 100).toFixed(0)}%

ã€ä½ çš„ä»»åŠ¡ã€‘ï¼š
1. **è¯­ä¹‰ä¼˜å…ˆ**ï¼šç†è§£ç”¨æˆ·çœŸæ­£æƒ³è¡¨è¾¾çš„ä»»åŠ¡æ„å›¾ï¼Œä¸è¦è¢«å‘éŸ³é”™è¯¯å¹²æ‰°
2. **å£éŸ³å®¹é”™**ï¼š
   - å¸¸è§éŸ³å˜ï¼šsh/sã€l/nã€in/ingã€f/hã€z/zhã€c/ch
   - ç²¤è¯­ç”¨è¯ï¼šä¹°å˜¢â†’ä¹°ä¸œè¥¿ã€åšå˜¢â†’åšäº‹ã€ç‡â†’çœ‹
   - å°æ™®ç”¨è¯ï¼šç­‰ä¸€ä¸‹ä¸‹â†’ç­‰ä¸€ä¸‹ã€æœ‰å¤Ÿâ†’å¾ˆ
   - åœ°æ–¹å£è¯­ï¼šåƒé¥­å’¯â†’åƒé¥­äº†ã€æå®šäº†å™»â†’æå®šäº†
3. **æ™ºèƒ½æ‹†åˆ†**ï¼šå¦‚æœæåˆ°å¤šä¸ªä»»åŠ¡ï¼ˆç”¨"å’Œ"ã€"è¿˜æœ‰"ã€"ç„¶å"ã€"ä»¥åŠ"è¿æ¥ï¼‰ï¼Œæ‹†åˆ†æˆå¤šä¸ªä»»åŠ¡
4. **ä¿ç•™å…³é”®è¯**ï¼šäººåã€åœ°ç‚¹ã€æ—¶é—´ã€å…·ä½“æ•°å­—å¿…é¡»ä¿ç•™

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
- rawText: åŸå§‹è¯†åˆ«æ–‡æœ¬ï¼ˆåŸå°ä¸åŠ¨ï¼‰
- correctedText: çº æ­£åçš„æ–‡æœ¬ï¼ˆå¦‚æœä¸éœ€è¦çº æ­£åˆ™ä¸åŸæ–‡ç›¸åŒï¼‰
- needsCorrection: æ˜¯å¦è¿›è¡Œäº†çº æ­£ï¼ˆtrue/falseï¼‰
- quests: ä»»åŠ¡åˆ—è¡¨

ã€ç¤ºä¾‹1ã€‘ï¼ˆå£éŸ³è¯†åˆ«é”™è¯¯ï¼‰ï¼š
è¾“å…¥ï¼š"æ˜æ—©ä¸ƒç‚¹è·‘ä¸äº”å…¬é‡Œ"
è¾“å‡ºï¼š
{
  "rawText": "æ˜æ—©ä¸ƒç‚¹è·‘ä¸äº”å…¬é‡Œ",
  "correctedText": "æ˜æ—©ä¸ƒç‚¹è·‘æ­¥äº”å…¬é‡Œ",
  "needsCorrection": true,
  "quests": [
    {
      "title": "ã€ä¿®ç‚¼ã€‘æ™¨æ›¦é•¿è·‘è¯•ç‚¼",
      "actionHint": "è·‘æ­¥5km@07:00",
      "tags": ["è¿åŠ¨"],
      "difficulty": "B",
      "rarity": "Common"
    }
  ]
}

ã€ç¤ºä¾‹2ã€‘ï¼ˆç²¤è¯­è¯æ±‡ï¼‰ï¼š
è¾“å…¥ï¼š"ä»Šæ—¥è¦ä¹°å˜¢åŒåšè¿åŠ¨"
è¾“å‡ºï¼š
{
  "rawText": "ä»Šæ—¥è¦ä¹°å˜¢åŒåšè¿åŠ¨",
  "correctedText": "ä»Šå¤©è¦ä¹°ä¸œè¥¿å’Œåšè¿åŠ¨",
  "needsCorrection": true,
  "quests": [
    {
      "title": "ã€æ”¶é›†ã€‘å¸‚é›†é‡‡è´­è¡ŒåŠ¨",
      "actionHint": "ä¹°ä¸œè¥¿",
      "tags": ["ç”Ÿæ´»"],
      "difficulty": "C",
      "rarity": "Common"
    },
    {
      "title": "ã€ä¿®ç‚¼ã€‘æ—¥å¸¸é”»ç‚¼è®¡åˆ’",
      "actionHint": "åšè¿åŠ¨",
      "tags": ["è¿åŠ¨"],
      "difficulty": "C",
      "rarity": "Common"
    }
  ]
}

è¯·å¤„ç†ç”¨æˆ·è¾“å…¥ï¼š`,
        response_json_schema: {
          type: "object",
          properties: {
            rawText: { type: "string" },
            correctedText: { type: "string" },
            needsCorrection: { type: "boolean" },
            quests: {
              type: "array",
              items: {
                type: "object",
                properties: {
                  title: { type: "string" },
                  actionHint: { type: "string" },
                  dueDate: { type: "string" },
                  tags: { type: "array", items: { type: "string" } },
                  difficulty: { type: "string", enum: ["C", "B", "A", "S"] },
                  rarity: { type: "string", enum: ["Common", "Rare", "Epic", "Legendary"] }
                }
              }
            }
          }
        }
      });

      // åœ¨ä»»åŠ¡ä¸­é™„åŠ åŸå§‹è¯­éŸ³æ–‡æœ¬å’Œçº æ­£ä¿¡æ¯
      const questsWithMetadata = result.quests.map(q => ({
        ...q,
        voiceRawText: result.rawText,
        voiceCorrectedText: result.needsCorrection ? result.correctedText : null,
        voiceConfidence: conf
      }));

      onQuestsGenerated(questsWithMetadata);
      setTranscript('');
      setConfidence(1);
    } catch (error) {
      console.error('æ–‡æœ¬å¤„ç†é”™è¯¯:', error);
      alert(`ä»»åŠ¡è§£æå¤±è´¥ï¼š${error.message || 'è¯·é‡è¯•'}`);
    }
    setIsProcessing(false);
  };

  return (
    <div 
      className="p-4 mb-6"
      style={{
        backgroundColor: '#FFE66D',
        border: '4px solid #000',
        boxShadow: '6px 6px 0px #000'
      }}
    >
      {!isRecording ? (
        <div className="flex gap-3 mb-3">
          <button
            onClick={startRecording}
            disabled={isProcessing}
            className="flex-shrink-0 w-16 h-16 flex items-center justify-center font-black transition-all"
            style={{
              backgroundColor: '#4ECDC4',
              border: '4px solid #000',
              boxShadow: '5px 5px 0px #000'
            }}
          >
            {isProcessing ? (
              <Loader2 className="w-8 h-8 animate-spin" />
            ) : (
              <Mic className="w-8 h-8" strokeWidth={3} />
            )}
          </button>

          <div className="flex-1">
            <input
              type="text"
              placeholder="è¾“å…¥ä»»åŠ¡æˆ–ç‚¹å‡»éº¦å…‹é£è¯´è¯..."
              value={transcript}
              onChange={(e) => setTranscript(e.target.value)}
              onKeyPress={(e) => {
                if (e.key === 'Enter') {
                  handleTextSubmit(transcript, 1);
                }
              }}
              disabled={isProcessing}
              className="w-full h-16 px-4 font-bold text-lg"
              style={{
                backgroundColor: '#FFF',
                border: '4px solid #000',
                boxShadow: '5px 5px 0px #000'
              }}
            />
          </div>

          <button
            onClick={() => handleTextSubmit(transcript, 1)}
            disabled={isProcessing || !transcript.trim()}
            className="flex-shrink-0 w-16 h-16 flex items-center justify-center font-black"
            style={{
              backgroundColor: '#C44569',
              color: '#FFF',
              border: '4px solid #000',
              boxShadow: '5px 5px 0px #000',
              opacity: (!transcript.trim() || isProcessing) ? 0.5 : 1
            }}
          >
            <Sparkles className="w-8 h-8" strokeWidth={3} />
          </button>
        </div>
      ) : (
        <div className="mb-3">
          <div 
            className="p-6 mb-3"
            style={{
              backgroundColor: '#FFF',
              border: '4px solid #000',
              boxShadow: '5px 5px 0px #000'
            }}
          >
            <div className="flex items-end justify-center gap-1 mb-4" style={{ height: '80px' }}>
              {audioLevels.map((level, i) => (
                <div
                  key={i}
                  className="transition-all duration-100 ease-out"
                  style={{
                    width: '8%',
                    height: `${Math.max(level * 100, 10)}%`,
                    backgroundColor: '#FF6B35',
                    border: '2px solid #000',
                    boxShadow: '2px 2px 0px #000'
                  }}
                />
              ))}
            </div>

            <div className="min-h-[40px] flex items-center justify-center">
              {transcript ? (
                <div>
                  <p className="font-bold text-lg text-center mb-2">{transcript}</p>
                  {confidence < 0.75 && (
                    <div className="flex items-center justify-center gap-2 text-orange-600">
                      <AlertCircle className="w-4 h-4" />
                      <span className="text-xs font-bold">
                        ç½®ä¿¡åº¦è¾ƒä½ï¼ŒAIå°†æ™ºèƒ½ç†è§£è¯­ä¹‰
                      </span>
                    </div>
                  )}
                </div>
              ) : (
                <p className="font-bold text-gray-400 text-center">æ­£åœ¨è†å¬...</p>
              )}
            </div>
          </div>

          <button
            onClick={stopRecording}
            className="w-full py-4 font-black uppercase text-lg flex items-center justify-center gap-3"
            style={{
              backgroundColor: '#FF6B35',
              color: '#FFF',
              border: '4px solid #000',
              boxShadow: '5px 5px 0px #000'
            }}
          >
            <MicOff className="w-6 h-6" strokeWidth={3} />
            å®Œæˆå½•éŸ³
          </button>
        </div>
      )}

      <div 
        className="flex items-start gap-2 p-3 mt-3"
        style={{
          backgroundColor: '#4ECDC4',
          border: '3px solid #000'
        }}
      >
        <AlertCircle className="w-5 h-5 flex-shrink-0 mt-0.5" strokeWidth={3} />
        <p className="text-xs font-bold leading-relaxed">
          ğŸ“¢ ä¹¦è®°å®˜æé†’ï¼šå³ä¾¿è¯­è°ƒå„å¼‚ï¼ˆç²¤è¯­ã€å°æ™®ã€åœ°æ–¹å£éŸ³ï¼‰ï¼Œå·¥ä¼šçš†èƒ½å¬æ‡‚ä½ çš„å§”æ‰˜ï¼Œè¯·å°½ç®¡å¼€å£å™è¿°ã€‚
        </p>
      </div>
    </div>
  );
}