
import { useState, useRef, useEffect } from 'react';
import { Mic, MicOff, Loader2, Sparkles, AlertCircle } from 'lucide-react';
import { base44 } from '@/api/base44Client';

export default function VoiceInput({ onQuestsGenerated }) {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [confidence, setConfidence] = useState(1);
  const [audioLevels, setAudioLevels] = useState([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]);
  const recognitionRef = useRef(null);
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const animationFrameRef = useRef(null);
  const streamRef = useRef(null);

  useEffect(() => {
    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  const startAudioVisualization = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;
      
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const analyser = audioContext.createAnalyser();
      const microphone = audioContext.createMediaStreamSource(stream);
      
      analyser.fftSize = 32;
      microphone.connect(analyser);
      
      audioContextRef.current = audioContext;
      analyserRef.current = analyser;

      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      
      const updateLevels = () => {
        if (!analyserRef.current) return;
        
        analyserRef.current.getByteFrequencyData(dataArray);
        
        const levels = [];
        const step = Math.floor(dataArray.length / 10);
        for (let i = 0; i < 10; i++) {
          const value = dataArray[i * step] / 255;
          levels.push(Math.min(value * 1.5, 1));
        }
        
        setAudioLevels(levels);
        animationFrameRef.current = requestAnimationFrame(updateLevels);
      };
      
      updateLevels();
    } catch (error) {
      console.error('æ— æ³•è®¿é—®éº¦å…‹é£:', error);
    }
  };

  const stopAudioVisualization = () => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    analyserRef.current = null;
    setAudioLevels([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]);
  };

  const startRecording = async () => {
    try {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      
      if (!SpeechRecognition) {
        alert('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼Œè¯·ä½¿ç”¨æ–‡æœ¬è¾“å…¥');
        return;
      }

      const recognition = new SpeechRecognition();
      
      // é…ç½®å¤šè¯­è¨€æ”¯æŒï¼Œæå‡å£éŸ³è¯†åˆ«
      recognition.lang = 'zh-CN';
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.maxAlternatives = 3; // è·å–å¤šä¸ªå€™é€‰ç»“æœ

      recognition.onstart = () => {
        setIsRecording(true);
        startAudioVisualization();
        console.log('è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨');
      };

      recognition.onresult = (event) => {
        let interimTranscript = '';
        let finalTranscript = '';
        let avgConfidence = 0;
        let confidenceCount = 0;

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const result = event.results[i];
          const transcriptText = result[0].transcript;
          
          // æ”¶é›†ç½®ä¿¡åº¦
          if (result[0].confidence !== undefined) {
            avgConfidence += result[0].confidence;
            confidenceCount++;
          }
          
          if (result.isFinal) {
            finalTranscript += transcriptText;
          } else {
            interimTranscript += transcriptText;
          }
        }

        // è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        if (confidenceCount > 0) {
          setConfidence(avgConfidence / confidenceCount);
        }

        setTranscript(finalTranscript || interimTranscript);
      };

      recognition.onerror = (event) => {
        console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);
        setIsRecording(false);
        stopAudioVisualization();
        if (event.error === 'no-speech') {
          alert('æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•');
        } else if (event.error === 'not-allowed') {
          alert('éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸ä½¿ç”¨éº¦å…‹é£');
        } else {
          alert(`è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼š${event.error}`);
        }
      };

      recognition.onend = () => {
        setIsRecording(false);
        stopAudioVisualization();
        console.log('è¯­éŸ³è¯†åˆ«å·²ç»“æŸ');
      };

      recognitionRef.current = recognition;
      recognition.start();
    } catch (error) {
      console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      alert('æ— æ³•å¯åŠ¨è¯­éŸ³è¯†åˆ«ï¼Œè¯·æ£€æŸ¥æµè§ˆå™¨æƒé™');
    }
  };

  const stopRecording = async () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      setIsRecording(false);
      stopAudioVisualization();
      
      if (transcript.trim()) {
        await handleTextSubmit(transcript, confidence);
      }
    }
  };

  const handleTextSubmit = async (text, conf = 1) => {
    if (!text.trim()) return;
    
    setIsProcessing(true);
    try {
      const result = await base44.integrations.Core.InvokeLLM({
        prompt: `ä½ æ˜¯å†’é™©è€…å·¥ä¼šçš„AIåŠ©æ‰‹ã€‚ç”¨æˆ·è¾“å…¥äº†ä»»åŠ¡æè¿°ï¼Œè¯·å°†å…¶è½¬æ¢ä¸ºRPGé£æ ¼çš„ä»»åŠ¡ã€‚

ç”¨æˆ·è¾“å…¥ï¼š"${text}"

è¦æ±‚ï¼š
1. å¦‚æœè¾“å…¥åŒ…å«å¤šä¸ªä»»åŠ¡ï¼ˆç”¨"å’Œ"ã€"è¿˜æœ‰"ã€"ç„¶å"ç­‰è¿æ¥ï¼‰ï¼Œæ‹†åˆ†æˆå¤šä¸ªä»»åŠ¡
2. ä¸ºæ¯ä¸ªä»»åŠ¡ç”ŸæˆRPGé£æ ¼çš„æ ‡é¢˜ã€éš¾åº¦ã€ç¨€æœ‰åº¦å’Œæ ‡ç­¾
3. æ ‡é¢˜æ ¼å¼ï¼šã€ä»»åŠ¡ç±»å‹ã€‘ä»»åŠ¡åç§°ï¼ˆç±»å‹å¦‚ï¼šè®¨ä¼ã€æ”¶é›†ã€æŠ¤é€ã€è°ƒæŸ¥ã€ä¿®ç‚¼ã€å¾æœã€æ¢ç´¢ï¼‰
4. ä¿ç•™å…³é”®ä¿¡æ¯ï¼šæ—¶é—´ã€åœ°ç‚¹ã€æ•°å­—ç­‰

éš¾åº¦è¯„çº§ï¼š
- Cçº§ï¼šè½»æ¾ä»»åŠ¡
- Bçº§ï¼šä¸­ç­‰æŒ‘æˆ˜
- Açº§ï¼šé«˜éš¾åº¦
- Sçº§ï¼šè¶…çº§æŒ‘æˆ˜

ç¤ºä¾‹ï¼š
è¾“å…¥ï¼š"æ˜æ—©7ç‚¹è·‘æ­¥5å…¬é‡Œï¼Œç„¶åä¹°èœ"
è¾“å‡ºï¼š
{
  "quests": [
    {
      "title": "ã€ä¿®ç‚¼ã€‘æ™¨æ›¦é•¿è·‘è¯•ç‚¼",
      "actionHint": "è·‘æ­¥5km@07:00",
      "tags": ["è¿åŠ¨"],
      "difficulty": "B",
      "rarity": "Common"
    },
    {
      "title": "ã€æ”¶é›†ã€‘å¸‚é›†é‡‡è´­è¡ŒåŠ¨",
      "actionHint": "ä¹°èœ",
      "tags": ["ç”Ÿæ´»"],
      "difficulty": "C",
      "rarity": "Common"
    }
  ]
}

è¯·ç”Ÿæˆï¼š`,
        response_json_schema: {
          type: "object",
          properties: {
            quests: {
              type: "array",
              items: {
                type: "object",
                properties: {
                  title: { type: "string" },
                  actionHint: { type: "string" },
                  dueDate: { type: "string" },
                  tags: { type: "array", items: { type: "string" } },
                  difficulty: { type: "string", enum: ["C", "B", "A", "S"] },
                  rarity: { type: "string", enum: ["Common", "Rare", "Epic", "Legendary"] }
                }
              }
            }
          }
        }
      });

      onQuestsGenerated(result.quests);
      setTranscript('');
      setConfidence(1);
    } catch (error) {
      console.error('æ–‡æœ¬å¤„ç†é”™è¯¯:', error);
      alert(`ä»»åŠ¡è§£æå¤±è´¥ï¼š${error.message || 'è¯·é‡è¯•'}`);
    }
    setIsProcessing(false);
  };

  return (
    <div 
      className="p-4 mb-6"
      style={{
        backgroundColor: '#FFE66D',
        border: '4px solid #000',
        boxShadow: '6px 6px 0px #000'
      }}
    >
      {!isRecording ? (
        <div className="flex gap-3 mb-3">
          <button
            onClick={startRecording}
            disabled={isProcessing}
            className="flex-shrink-0 w-16 h-16 flex items-center justify-center font-black transition-all"
            style={{
              backgroundColor: '#4ECDC4',
              border: '4px solid #000',
              boxShadow: '5px 5px 0px #000'
            }}
          >
            {isProcessing ? (
              <Loader2 className="w-8 h-8 animate-spin" />
            ) : (
              <Mic className="w-8 h-8" strokeWidth={3} />
            )}
          </button>

          <div className="flex-1">
            <input
              type="text"
              placeholder="è¾“å…¥ä»»åŠ¡æˆ–ç‚¹å‡»éº¦å…‹é£è¯´è¯..."
              value={transcript}
              onChange={(e) => setTranscript(e.target.value)}
              onKeyPress={(e) => {
                if (e.key === 'Enter') {
                  handleTextSubmit(transcript, 1);
                }
              }}
              disabled={isProcessing}
              className="w-full h-16 px-4 font-bold text-lg"
              style={{
                backgroundColor: '#FFF',
                border: '4px solid #000',
                boxShadow: '5px 5px 0px #000'
              }}
            />
          </div>

          <button
            onClick={() => handleTextSubmit(transcript, 1)}
            disabled={isProcessing || !transcript.trim()}
            className="flex-shrink-0 w-16 h-16 flex items-center justify-center font-black"
            style={{
              backgroundColor: '#C44569',
              color: '#FFF',
              border: '4px solid #000',
              boxShadow: '5px 5px 0px #000',
              opacity: (!transcript.trim() || isProcessing) ? 0.5 : 1
            }}
          >
            <Sparkles className="w-8 h-8" strokeWidth={3} />
          </button>
        </div>
      ) : (
        <div className="mb-3">
          <div 
            className="p-6 mb-3"
            style={{
              backgroundColor: '#FFF',
              border: '4px solid #000',
              boxShadow: '5px 5px 0px #000'
            }}
          >
            <div className="flex items-end justify-center gap-1 mb-4" style={{ height: '80px' }}>
              {audioLevels.map((level, i) => (
                <div
                  key={i}
                  className="transition-all duration-100 ease-out"
                  style={{
                    width: '8%',
                    height: `${Math.max(level * 100, 10)}%`,
                    backgroundColor: '#FF6B35',
                    border: '2px solid #000',
                    boxShadow: '2px 2px 0px #000'
                  }}
                />
              ))}
            </div>

            <div className="min-h-[40px] flex items-center justify-center">
              {transcript ? (
                <p className="font-bold text-lg text-center">{transcript}</p>
              ) : (
                <p className="font-bold text-gray-400 text-center">æ­£åœ¨è†å¬...</p>
              )}
            </div>
          </div>

          <button
            onClick={stopRecording}
            className="w-full py-4 font-black uppercase text-lg flex items-center justify-center gap-3"
            style={{
              backgroundColor: '#FF6B35',
              color: '#FFF',
              border: '4px solid #000',
              boxShadow: '5px 5px 0px #000'
            }}
          >
            <MicOff className="w-6 h-6" strokeWidth={3} />
            å®Œæˆå½•éŸ³
          </button>
        </div>
      )}

      <div 
        className="flex items-start gap-2 p-3 mt-3"
        style={{
          backgroundColor: '#4ECDC4',
          border: '3px solid #000'
        }}
      >
        <AlertCircle className="w-5 h-5 flex-shrink-0 mt-0.5" strokeWidth={3} />
        <p className="text-xs font-bold leading-relaxed">
          ğŸ“¢ ä¹¦è®°å®˜æé†’ï¼šå³ä¾¿è¯­è°ƒå„å¼‚ï¼ˆç²¤è¯­ã€å°æ™®ã€åœ°æ–¹å£éŸ³ï¼‰ï¼Œå·¥ä¼šçš†èƒ½å¬æ‡‚ä½ çš„å§”æ‰˜ï¼Œè¯·å°½ç®¡å¼€å£å™è¿°ã€‚
        </p>
      </div>
    </div>
  );
}
